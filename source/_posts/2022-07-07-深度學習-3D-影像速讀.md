---
title: 深度學習 3D 影像速讀
mathjax: false
date: 2022-07-07 13:50:46
tags: 3D image
categories: 電腦視覺整理
---

實驗室未來有可能要做 3D 的影像處理，來寫一篇筆記記錄一下我從 0 開始學什麼是 3D 影像

keywords: point cloud、voxel
<!--more-->

## 怎麼得到 3D 的影像？

一種方式是模仿人類使用「立體視覺法」，利用兩個不同角度的攝影機去對同一個物體拍攝，就可以利用同一個點不同位置的資訊去建構出 3D 的立體影像。

<img src="https://i.imgur.com/dPoZfBs.png" alt="image-20220704201640180" style="zoom:50%;" />

而另一種則是使用 TOF 「飛行時間法」，最有名的例子是 RGB-D 格式，每一個影像上的像素都會額外在新增一維「深度維」，利用計算雷射光來回的時間差就可得知，微軟的 Kincet 是最有名的攝影機

<img src="https://i.imgur.com/kN7t2Wv.png" alt="image-20220704201938901" style="zoom:50%;" />

第三種是雷射雷達 LiDAR，與上面的 TOF 原理類似，只不過 LiDAR 能往同心圓四面八方發射，且發射的距離可遠的多，與之對應的儲存格式是 point cloud

<img src="https://i.imgur.com/r5WJTGa.png" alt="image-20220704201955493" style="zoom:50%;" />

## 怎麼在電腦中表示？

我們有了許多 3D 影像的各種資訊，我們怎麼統一表示這些資訊，或是有什麼格式可以遵循嗎？

以下格式由左至右是：point cloud 點雲、voxel 體素、mesh 三角多邊型網格、multi-view 多視角集合

![image-20220704202332900](https://i.imgur.com/TppWMka.png)

(a) 所謂 point cloud 多半是指從 LiDAR 收集而來的影像資料，它是由一個個互相「獨立」的點所構成，每一個都會包含很多資訊：RGB 顏色、深度、來回時間…，而 point cloud 的優點為：資料不太需要二次處理，即收集即能用，且表示出的 3D 影像較不失真；而 point cloud 的缺點也與好是它的反面：point cloud 大多是「無序」的，也可看成它是一個集合，這個集合中的點相互交換對網路的輸出結果應該要是不會變的，同時因它沒有「座標表示」，現有的 CNN 架構無法直接使用上

(b) voxel 體素一詞是由 pixel 像素變化而來，特指 3D 上的 pixel 影像，也有人稱這種型式叫 2.5D。voxel 也想成由需多二維切片影像，一個疊一個，疊出一個三維的表示，voxel 最常應用在醫學的斷層掃描上。voxel 的優點是有座標系統，可以直接使用現成的 CNN 模型來達成；缺點是：需要影像二次處理，point cloud 影像需要經 Occupancy Grid Map (占據網格網路) 轉換為 Voxel (詳細方法可參考以下文章：[占据栅格地图（Occupancy Grid Map）知乎](https://zhuanlan.zhihu.com/p/21738718)，且因有座標系所有存在失真的問題

(c) mesh 多邊型，常常應用在 3D 圖學上，多用於建模，而常見的處理方式可以利用 GNN Graph 的方式去處理 (這個我比較不清楚，就不多細說了)

(d) multi-view，則是我們放置了許許多多的攝影機去拍攝同一物體，我們期望藉由影像相互之間的關系，去建構出 3D 關系圖

## 發展歷史

### VoxNet

2015 年 由 Daniel Maturana 提出 VoxNet 來解決 voxel 格式的深度學習辨識，他們的作法也很直覺暴力。先把 point cloud 經 occupancy grid 做二次處理得到 voxel 表示，再經過許多的 3D Conv 提取特徵，最後得到結果

<img src="https://i.imgur.com/hnROSsl.png" alt="image-20220704203925739" style="zoom:50%;" />

這個 3D Conv 之所以可行，是因為這也只是維度上的問題而已，反正只要能確保兩矩陣乘法最後乘出來的維度是相同的就可以了

### MVCNN

緊接著也在 2015 年發了 Multi-view Convolutional Neural Networks for 3D Shape Recognition 這篇論文，提出 MVCNN 架構，這裡則是使用 Multi-view 的角度去解決 3D 影像問題，其中 CNN 也是用 3D CNN

<img src="https://i.imgur.com/czm9ywc.png" alt="image-20220704204431276" style="zoom:50%;" />

### PointNet 系列

在 2016 年提出 PointNet 正式開起了直接使用 PointNet 的網路架構，而在這之後，需多的論文也是從 point cloud 的角度作為出發點改進…

### 醫學斷層掃描系列

MRI 核磁共震，就是 voxel 影像的最佳代表，一個完全不用二次處理原汁原味的 voxel 影像，我有看到幾篇相關論文，列舉在這邊：2020 Satya P. Singh 提出 [3D Deep Learning on Medical Images: A Review](https://arxiv.org/pdf/2004.00218.pdf) 、2020 Hasib Zunair提出 [Uniformizing Techniques to Process CT scans with 3D CNNs for Tuberculosis Prediction](https://arxiv.org/pdf/2007.13224.pdf) 、2018 EMAN AHMED 提出 [A survey on Deep Learning Advances on Different 3D Data Representations](https://arxiv.org/pdf/1808.01462.pdf)

上述這些論文的共同特色就是「魔改 CNN」，一路把 VGG、ResNet、Inception、DenseNet... 把裡面全部的 2D Conv 全換為 3D Conv 就完事了

## Reference

### 3D 影像導論

[point_cloud_segmentation的发展过程 (csdn)](https://blog.csdn.net/weixin_40805392/article/details/98729367)

[3D 影像歷史介紹 (英文，大推)](https://thegradient.pub/beyond-the-pixel-plane-sensing-and-learning-in-3d/)

[上面那篇的中文翻釋 (照抄…)](https://www.jiqizhixin.com/articles/091203)

[3D点云基础知识(一)](https://cxyzjd.com/article/xiaoyaolangwj/113572662)

### 論文集合

[VoxNet](https://www.ri.cmu.edu/pub_files/2015/9/voxnet_maturana_scherer_iros15.pdf)



